{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from utils import load_wildfire_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Resize((128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw data: (12500, 256, 256)\n",
      "Size of raw data after reshape: (125, 100, 256, 256)\n",
      "Size of raw data: (5000, 256, 256)\n",
      "Size of raw data after reshape: (50, 100, 256, 256)\n",
      "Train size: 9900\n",
      "Validation size: 2475\n",
      "Total data size: 12375\n",
      "Train input size: torch.Size([1, 128, 128])\n",
      "Train target size: torch.Size([1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl, test_dl = load_wildfire_data(batch_size=32, shuffle=True, train_ratio = 0.8, root='data/', seq_length=1, sample_rate = 1, transform=transform, time_embedding=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: VQ-VAE 2D Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost=0.25):\n",
    "        super(VQVAE, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.commitment_cost = commitment_cost\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(256*256, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(1024, 512),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(512, 1024),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256*256),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Codebook\n",
    "        self.codebook = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.codebook.weight.data.uniform_(-1/num_embeddings, 1/num_embeddings)\n",
    "\n",
    "    def encode(self, x):\n",
    "        z_e = self.encoder(x)\n",
    "        return z_e\n",
    "\n",
    "    def quantize(self, z_e):\n",
    "        \n",
    "        distances = (z_e ** 2).sum(dim=1, keepdim=True) + (self.codebook.weight ** 2).sum(dim=1) - 2 * torch.matmul(\n",
    "            z_e, self.codebook.weight.t())\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        z_q = self.codebook(encoding_indices).view(z_e.shape)\n",
    "        return z_q, encoding_indices\n",
    "\n",
    "    def decode(self, z_q):\n",
    "        x_recon = self.decoder(z_q)\n",
    "        return x_recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.size())\n",
    "        z_e = self.encode(x)\n",
    "        # print(z_e.size())\n",
    "        z_q, encoding_indices = self.quantize(z_e)\n",
    "        x_recon = self.decode(z_q)\n",
    "        x_recon = x.view(x.size(0), 1, 256, 256)\n",
    "\n",
    "        # Commitment loss\n",
    "        e_latent_loss = F.mse_loss(z_e, z_q.detach())\n",
    "        q_latent_loss = F.mse_loss(z_q, z_e.detach())\n",
    "        loss = q_latent_loss + self.commitment_cost * e_latent_loss\n",
    "\n",
    "        return x_recon, loss, z_e, z_q\n",
    "    \n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "model = VQVAE(num_embeddings=128, embedding_dim=64, commitment_cost=0.25)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for inputs, targets in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\"):\n",
    "    \n",
    "    #for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, loss, z_e, z_q = model(inputs)\n",
    "        recon_loss = F.mse_loss(outputs, targets)\n",
    "        total_loss = recon_loss + loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "    \n",
    "    epoch_loss /= len(train_dl)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3bd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
